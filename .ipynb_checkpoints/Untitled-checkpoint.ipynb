{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sklearn \n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cat = ['business','entertainment']\n",
    "#do not load filecontents\n",
    "datas =load_files('datasets/bbc/' ,categories=cat ,load_content=True ,shuffle=True, encoding='utf8', decode_error = 'strict' , random_state=0)                 \n",
    "\n",
    "tfidf = TfidfVectorizer(encoding='utf8', decode_error='strict', tokenizer=None, analyzer='word', stop_words=None ,ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None,binary=False, norm='l2', use_idf= True, smooth_idf=True,sublinear_tf=False )\n",
    "X = tfidf.fit_transform(datas.data)\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "if not os.path.exists(\"directory\"):\n",
    "    os.makedirs(\"directory\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "1251 documents\n",
      "5 categories\n",
      "*******************\n",
      "['/home/mabrin/project/cluster/datasets/bbcTest/politics/107.txt'\n",
      " '/home/mabrin/project/cluster/datasets/bbcTest/tech/055.txt'\n",
      " '/home/mabrin/project/cluster/datasets/bbcTest/business/154.txt' ...,\n",
      " '/home/mabrin/project/cluster/datasets/bbcTest/entertainment/225.txt'\n",
      " '/home/mabrin/project/cluster/datasets/bbcTest/entertainment/069.txt'\n",
      " '/home/mabrin/project/cluster/datasets/bbcTest/tech/156.txt']\n",
      "*****************************************************\n",
      "(1126, 175)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mabrin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/mabrin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 175 while Y.shape[1] == 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-6409344c2d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         clust.append(sklearn.metrics.pairwise.euclidean_distances(x , y,\n\u001b[0;32m---> 70\u001b[0;31m                         Y_norm_squared=None, squared=False, X_norm_squared=None))\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mabrin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mpaired_distances\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0mbetweens\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0mof\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_norm_squared\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mabrin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    120\u001b[0m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[1;32m    121\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[0;32m--> 122\u001b[0;31m                              X.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 175 while Y.shape[1] == 1"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import sklearn.datasets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "from sklearn.cluster import Birch\n",
    "import sklearn\n",
    "\n",
    "categories = [\n",
    "   \"business\" ,\"sport\" , 'entertainment', 'tech','politics']\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "#print(categories)\n",
    "\n",
    "dataset = sklearn.datasets.load_files('/home/mabrin/project/cluster/datasets/bbcTest/',\n",
    "                                      description=None, categories=categories ,\n",
    "                                      load_content=True, shuffle=True, encoding = 'utf-8',decode_error='ignore',\n",
    "                                      random_state=25)\n",
    "\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "print(\"*******************\")\n",
    "#print(dataset.target)\n",
    "true_k = 5\n",
    "print(dataset.filenames)\n",
    "vectorizer = TfidfVectorizer(max_df=.3, max_features=175 ,\n",
    "                                 min_df=10\n",
    "                             , stop_words='english',\n",
    "                                 use_idf=True)\n",
    "#print(type(dataset.data))\n",
    "\n",
    "\n",
    "Y = vectorizer.fit_transform(dataset.data[125:])\n",
    "\n",
    "cur = Y.toarray()\n",
    "\n",
    "X = vectorizer.fit_transform(dataset.data[:125])\n",
    "\n",
    "km = MiniBatchKMeans(n_clusters=true_k, init='k-means++', n_init=1,init_size=1000, batch_size=1000)\n",
    "km.fit(X)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "clusters = defaultdict(list)\n",
    "\n",
    "k = 0;\n",
    "for i in km.labels_ :\n",
    "  clusters[i].append(dataset.filenames[k])  \n",
    "  k += 1\n",
    "  \n",
    "'''for clust in clusters :\n",
    "  print (\"\\n************************\\n\")\n",
    "  for filename in clusters[clust] :\n",
    "    print (filename)'''\n",
    "print(\"*****************************************************\")\n",
    "\n",
    "print(Y.shape)\n",
    "for i in range(125,Y.shape[0]):\n",
    "    clust = []\n",
    "    for j in range (5):\n",
    "        x = km.cluster_centers_[j]\n",
    "        y = cur[i]\n",
    "        clust.append(sklearn.metrics.pairwise.euclidean_distances(x , y,\n",
    "                        Y_norm_squared=None, squared=False, X_norm_squared=None))\n",
    "    print(np.argmin(clust))\n",
    "    print(i)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "'''for i in range(true_k):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :200]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()'''\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
